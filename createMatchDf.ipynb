{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8375b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_matches_for_league(league_shortcut: str, season: int = 2025):\n",
    "    \"\"\"\n",
    "    Lädt alle Spiele einer Liga (1., 2. oder 3. Bundesliga) von OpenLigaDB.\n",
    "    league_shortcut: 'bl1', 'bl2', 'bl3'\n",
    "    season: Jahr der Saison (z. B. 2024 für Saison 2024/25)\n",
    "    \"\"\"\n",
    "    urlOpenLigaDB = f\"https://api.openligadb.de/getmatchdata/{league_shortcut}/{season}\"\n",
    "    r = requests.get(urlOpenLigaDB)\n",
    "    data = r.json()\n",
    "\n",
    "    matches = []\n",
    "    for match in data:\n",
    "        matches.append({\n",
    "            \"league\": league_shortcut,\n",
    "            \"match_id\": match[\"matchID\"],\n",
    "            \"date\": match[\"matchDateTime\"],\n",
    "            \"matchday\": match[\"group\"][\"groupName\"],\n",
    "            \"team_home\": match[\"team1\"][\"teamName\"],\n",
    "            \"team_away\": match[\"team2\"][\"teamName\"],\n",
    "            #\"city\": match[\"location\"][\"locationCity\"],\n",
    "            #\"stadium\": match[\"location\"][\"locationStadium\"]\n",
    "        })\n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "\n",
    "# Abruf für 1.–3. Bundesliga\n",
    "df_matches_bl1 = get_matches_for_league(\"bl1\", 2025)\n",
    "df_matches_bl2 = get_matches_for_league(\"bl2\", 2025)\n",
    "df_matches_bl3 = get_matches_for_league(\"bl3\", 2025)\n",
    "\n",
    "# Zusammenführen\n",
    "df_matches = pd.concat([df_matches_bl1, df_matches_bl2, df_matches_bl3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beba6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def scrape_transfermarkt_stadiums(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for row in soup.select(\"table.items > tbody > tr\"):\n",
    "        # optional: nur echte Datenzeilen, klassisch 'odd' oder 'even'\n",
    "        if 'class' in row.attrs and not any(c in ['odd', 'even'] for c in row['class']):\n",
    "            continue\n",
    "\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) >= 5:\n",
    "            # Teamname aus img title\n",
    "            team_img = cols[1].find(\"img\")\n",
    "            team = team_img['title'].strip() if team_img else cols[1].get_text(strip=True)\n",
    "\n",
    "            # Stadion, Ort, Kapazität\n",
    "            stadion = cols[2].get_text(strip=True)\n",
    "            ort = cols[3].get_text(strip=True)\n",
    "            kapaz_raw = cols[4].get_text(strip=True).replace(\".\", \"\")\n",
    "            \n",
    "            # Nur Zeilen mit gültiger Kapazität übernehmen\n",
    "            try:\n",
    "                kapaz = int(kapaz_raw)\n",
    "                if kapaz < 1000:  # Filter: reale Stadien > 1000 Plätze\n",
    "                    continue\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            data.append([team, stadion, ort, kapaz])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"team\", \"stadium\", \"city\", \"capacity\"])\n",
    "\n",
    "\n",
    "urls = {\n",
    "    \"1. Bundesliga\": \"https://www.transfermarkt.de/bundesliga/stadien/wettbewerb/L1\",\n",
    "    \"2. Bundesliga\": \"https://www.transfermarkt.de/2-bundesliga/stadien/wettbewerb/L2\",\n",
    "    \"3. Liga\": \"https://www.transfermarkt.de/3-liga/stadien/wettbewerb/L3\"\n",
    "}\n",
    "\n",
    "df_stadiums_list = []\n",
    "for liga, url in urls.items():\n",
    "    df = scrape_transfermarkt_stadiums(url)\n",
    "    df_stadiums_list.append(df)\n",
    "\n",
    "df_stadiums = pd.concat(df_stadiums_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ddd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add location of nearest train station\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"bundesliga-bahn-mapper\")\n",
    "\n",
    "def find_nearest_station(city):\n",
    "    try:\n",
    "        query = f\"{city} Hauptbahnhof\"\n",
    "        location = geolocator.geocode(query)\n",
    "        if location:\n",
    "            return {\n",
    "                \"station_name\": query,\n",
    "                \"lat\": location.latitude,\n",
    "                \"lon\": location.longitude\n",
    "            }\n",
    "        else:\n",
    "            # fallback: Stadtzentrum\n",
    "            city_loc = geolocator.geocode(city)\n",
    "            if city_loc:\n",
    "                return {\n",
    "                    \"station_name\": f\"{city} (Zentrum)\",\n",
    "                    \"lat\": city_loc.latitude,\n",
    "                    \"lon\": city_loc.longitude\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {city}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Alle einzigartigen Städte extrahieren\n",
    "cities = pd.Series(df_stadiums[\"city\"].dropna().unique()).tolist()\n",
    "\n",
    "# Koordinaten sammeln\n",
    "station_data = {}\n",
    "for city in cities:\n",
    "    result = find_nearest_station(city)\n",
    "    if result:\n",
    "        station_data[city] = result\n",
    "    time.sleep(1)  # WICHTIG: Rate-Limit der OSM-API\n",
    "\n",
    "# Ergebnisse in DataFrame-Form\n",
    "df_stations = pd.DataFrame.from_dict(station_data, orient=\"index\")\n",
    "\n",
    "# Reset the index so that the city names become a column\n",
    "df_stations = df_stations.reset_index().rename(columns={\"index\": \"city\"})\n",
    "\n",
    "# merge \n",
    "df_teams = df_stadiums.merge(df_stations, how = \"left\", left_on = \"city\", right_on = \"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a04b1f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>stadium</th>\n",
       "      <th>city</th>\n",
       "      <th>capacity</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>team_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>SIGNAL IDUNA PARK</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>81365</td>\n",
       "      <td>Dortmund Hauptbahnhof</td>\n",
       "      <td>51.517064</td>\n",
       "      <td>7.461138</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FC Bayern München</td>\n",
       "      <td>Allianz Arena</td>\n",
       "      <td>München</td>\n",
       "      <td>75000</td>\n",
       "      <td>München Hauptbahnhof</td>\n",
       "      <td>48.140725</td>\n",
       "      <td>11.556943</td>\n",
       "      <td>FC Bayern München</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VfB Stuttgart</td>\n",
       "      <td>MHPArena Stuttgart</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>60449</td>\n",
       "      <td>Stuttgart Hauptbahnhof</td>\n",
       "      <td>48.784266</td>\n",
       "      <td>9.182117</td>\n",
       "      <td>VfB Stuttgart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eintracht Frankfurt</td>\n",
       "      <td>Deutsche Bank Park</td>\n",
       "      <td>Frankfurt (Main)</td>\n",
       "      <td>59500</td>\n",
       "      <td>Frankfurt (Main) Hauptbahnhof</td>\n",
       "      <td>50.106654</td>\n",
       "      <td>8.662581</td>\n",
       "      <td>Eintracht Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamburger SV</td>\n",
       "      <td>Volksparkstadion</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>57000</td>\n",
       "      <td>Hamburg Hauptbahnhof</td>\n",
       "      <td>53.553199</td>\n",
       "      <td>10.006436</td>\n",
       "      <td>Hamburger SV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  team             stadium              city  capacity  \\\n",
       "0    Borussia Dortmund   SIGNAL IDUNA PARK          Dortmund     81365   \n",
       "1    FC Bayern München       Allianz Arena           München     75000   \n",
       "2        VfB Stuttgart  MHPArena Stuttgart         Stuttgart     60449   \n",
       "3  Eintracht Frankfurt  Deutsche Bank Park  Frankfurt (Main)     59500   \n",
       "4         Hamburger SV    Volksparkstadion           Hamburg     57000   \n",
       "\n",
       "                    station_name        lat        lon           team_clean  \n",
       "0          Dortmund Hauptbahnhof  51.517064   7.461138    Borussia Dortmund  \n",
       "1           München Hauptbahnhof  48.140725  11.556943    FC Bayern München  \n",
       "2         Stuttgart Hauptbahnhof  48.784266   9.182117        VfB Stuttgart  \n",
       "3  Frankfurt (Main) Hauptbahnhof  50.106654   8.662581  Eintracht Frankfurt  \n",
       "4           Hamburg Hauptbahnhof  53.553199  10.006436         Hamburger SV  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3251ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "# Dictionary: Stadium-Teamname → gewünschtes Match-Name\n",
    "mapping_teamNames = {}\n",
    "for m in df_matches[\"team_home\"].unique():\n",
    "    match_best = process.extractOne(m, df_stadiums[\"team\"].unique())\n",
    "    mapping_teamNames[match_best[0]] = m\n",
    "\n",
    "# df_stadiums direkt ersetzen oder neue Spalte erzeugen\n",
    "df_teams[\"team_clean\"] = df_teams[\"team\"].replace(mapping_teamNames)\n",
    "\n",
    "# merge dfs\n",
    "df_merged1 = df_matches.merge(df_teams, how = \"left\", left_on=\"team_home\", right_on=\"team_clean\", indicator=True)\n",
    "# Überprüfen\n",
    "## df_merged[df_merged[\"_merge\"] == \"left_only\"][\"team_home\"].unique()\n",
    "## print(df_merged[\"_merge\"].value_counts())\n",
    "\n",
    "# add away city\n",
    "df_merged2 = df_merged1.merge(df_teams[[\"team_clean\", \"city\", \"station_name\", \"lat\", \"lon\"]].rename(columns = {\"city\":\"away_city\", 'station_name':\"away_station\", 'lat':\"away_lat\", 'lon':\"away_lon\"}), how = \"left\", left_on=\"team_away\", right_on=\"team_clean\")\n",
    "\n",
    "\n",
    "\n",
    "# Select Spalten\n",
    "df_full = df_merged2[['match_id', 'league', 'date', 'matchday', 'team_home', 'team_away', 'stadium', 'capacity', 'city', 'away_city', \"station_name\", \"lat\", \"lon\", \"away_station\", \"away_lat\", \"away_lon\"]].rename(columns = {'city':\"home_city\", 'station_name':\"home_station\", 'lat':\"home_lat\", 'lon':\"home_lon\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6f6179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv(\"matchInfos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44517aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1572c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321294d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
